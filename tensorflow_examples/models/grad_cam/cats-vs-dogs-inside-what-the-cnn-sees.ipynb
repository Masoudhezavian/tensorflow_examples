{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport keras.backend as K\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport random\nimport seaborn as sns\nimport os\nfrom PIL import Image\nimport cv2\ntf.compat.v1.disable_eager_execution()\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_dir='../input/dogs-cats-images/dataset/training_set'\ntest_dir='../input/dogs-cats-images/dataset/test_set'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cats=os.listdir(train_dir+'/'+'cats')\ntrain_dogs=os.listdir(train_dir+'/'+'dogs')\ntest_cats=os.listdir(test_dir+'/'+'cats')\ntest_dogs=os.listdir(test_dir+'/'+'dogs')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The Test Data is {}% of the Train Data'.format((len(test_cats+test_dogs)/len(train_cats+train_dogs))*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,5))\nax1.bar(x=['Cat','Dog'],height=[len(train_cats),len(train_dogs)],color=['gray','k'])\nax1.set_title('Train Class Balance')\nax2.bar(x=['Cat','Dog'],height=[len(test_cats),len(test_dogs)],color=['gray','k'])\nax2.set_title('Test Class Balance')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_sample_images(k):\n    plt.figure()\n    cat_imgs=random.choices(train_cats,k=k)\n    dog_imgs=random.choices(train_dogs,k=k)\n    fig,ax=plt.subplots(2,k,figsize=(15,10))\n    for i in range(k):\n        img_cat=Image.open(train_dir+'/cats/'+cat_imgs[i])\n        img_dog=Image.open(train_dir+'/dogs/'+dog_imgs[i])\n        ax[0,i].imshow(img_cat)\n        ax[1,i].imshow(img_dog)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_sample_images(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dog_img=random.choice(train_dogs)\ndog_img=np.array(Image.open(train_dir+'/dogs/'+dog_img))\ndog_img_scaled=np.array(dog_img)/255\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,5))\nax1.imshow(dog_img)\nax1.set_title('Original Image')\nax2.imshow(dog_img_scaled)\nax2.set_title('Scaled Image')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen=ImageDataGenerator(rescale=1/255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen=datagen.flow_from_directory(train_dir,\n                                      target_size=(150,150),\n                                      batch_size=batch_size,\n                                      class_mode='binary')\ntest_gen=datagen.flow_from_directory(test_dir,\n                                      target_size=(150,150),\n                                      batch_size=batch_size,\n                                      class_mode='binary')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape =(150,150,3)))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    model.add(Dropout(rate = 0.3))\n    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    model.add(Dropout(rate = 0.2))\n    model.add(Conv2D(filters = 126, kernel_size = (3, 3), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    model.add(Dropout(rate = 0.15))\n    model.add(Flatten())\n    model.add(Dense(units = 32, activation = 'relu'))\n    model.add(Dropout(rate = 0.15))\n    model.add(Dense(units = 64, activation = 'relu'))\n    model.add(Dropout(rate = 0.1))\n    model.add(Dense(units = 2, activation = 'softmax'))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model=get_model()\nbase_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=base_model.fit(train_gen,validation_data=test_gen,epochs=5,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.DataFrame(history.history)\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,5))\n\nax1.plot(df[['loss','val_loss']])\nax1.legend(['loss','val_loss'])\nax1.set_title('Loss per Epoch')\n\nax2.plot(df[['acc','val_acc']])\nax2.legend(['acc','val_acc'])\nax2.set_title('Accuracy per Epoch')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_outputs(model):\n    layer_names=[]\n    outputs=[]\n    for layer in model.layers:\n        if ('conv2d' in layer.name) or ('pooling' in layer.name) :\n            layer_names.append(layer.name)\n            outputs.append(layer.output)\n    return layer_names,outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layer_names,outputs=get_outputs(base_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Model(base_model.input,outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vis_activations(img,model,layer_names):\n    activations=model.predict(img)\n    images_per_row=16\n    for layer_name,activation in zip(layer_names,activations):\n        nb_features=activation.shape[-1]\n        size=activation.shape[1]\n        \n        nb_cols=nb_features//images_per_row\n        grid=np.zeros((size*nb_cols,size*images_per_row))\n        \n        for col in range(nb_cols):\n            for row in range(images_per_row):\n                feature_map=activation[0,:,:,col*images_per_row+row]\n                feature_map-=feature_map.mean()\n                feature_map/=feature_map.std()\n                feature_map*=255\n                feature_map=np.clip(feature_map,0,255).astype(np.uint8)\n                grid[col*size:(col+1)*size, row*size:(row+1)*size] = feature_map\n        scale = 1./size\n        plt.figure(figsize=(scale*grid.shape[1], scale*grid.shape[0]))\n        plt.title(layer_name)\n        plt.grid(False)\n        plt.imshow(grid, aspect='auto', cmap='viridis')\n    plt.show()\n    return activations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=train_gen.next()[0][0,:,:,:].reshape(-1,150,150,3)\nactivations=vis_activations(img,model,layer_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_Cam(img,label):\n    predicted_output=base_model.output[:,label]\n    last_conv_layer=base_model.get_layer(layer_names[-2])\n    \n    grads=K.gradients(predicted_output,last_conv_layer.output)[0]\n    \n    grads = K.mean(grads,axis=(0,1,2))\n    evaluation_function=K.function([base_model.input],[grads,last_conv_layer.output[0]])\n    \n    grads_values,conv_output_values=evaluation_function(img)\n    \n    for i in range(126):\n        conv_output_values[:,:,i]*=grads_values[i]\n    \n    \n    heatmap=np.mean(conv_output_values,axis=-1)\n    \n    heatmap=np.maximum(heatmap,0)\n    \n    heatmap/=heatmap.max()\n    \n    return heatmap\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import data, color, io, img_as_float","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_random():\n    b=test_gen.next()\n    img=b[0][0,:,:,:]\n\n    label=b[1][0]\n    img=np.expand_dims(img,axis=0)\n    pred_label = np.argmax(base_model.predict(img), axis=-1)[0]\n    \n    activations=model.predict(img)\n    activation=activations[0][0,:,:,7]\n    \n    activation-=activation.mean()\n    activation/=activation.std()\n    activation*=255\n    activation=np.clip(activation,0,255).astype(np.uint8)\n    \n    heatmap=get_Cam(img,pred_label)\n    heatmap = cv2.resize(heatmap, (150, 150))\n    heatmap = heatmap *255\n    heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    \n    img=img[0,:,:,:]\n    sample_image_hsv = color.rgb2hsv(img)\n    heatmap = color.rgb2hsv(heatmap)\n    alpha=0.5\n    sample_image_hsv[..., 0] = heatmap[..., 0]\n    sample_image_hsv[..., 1] = heatmap[..., 1] * alpha\n\n    img_masked = color.hsv2rgb(sample_image_hsv)\n \n    super_imposed_image =heatmap*0.5+img\n    super_imposed_image = np.clip(super_imposed_image, 0,255).astype(np.uint8)\n    \n    f,ax = plt.subplots(2,2, figsize=(15,8))\n    ax[0,0].imshow(img)\n    ax[0,0].set_title(f\"True label: {label} \\n Predicted label: {pred_label}\")\n    ax[0,0].axis('off')\n    \n    ax[0,1].imshow(activation)\n    ax[0,1].set_title(\"Random feature map\")\n    ax[0,1].axis('off')\n    \n    ax[1,0].imshow(color.hsv2rgb(heatmap))\n    ax[1,0].set_title(\"Class Activation Map\")\n    ax[1,0].axis('off')\n    \n    ax[1,1].imshow(img_masked)\n    ax[1,1].set_title(\"Activation map superimposed\")\n    ax[1,1].axis('off')\n    \n    plt.show()\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_random()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}